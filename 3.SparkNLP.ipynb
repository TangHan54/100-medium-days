{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4xCgPbQJwg",
        "colab_type": "text"
      },
      "source": [
        "0. Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYaTPXrP9bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1cf87d12-d610-49ae-d9a0-5689c140c23e"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 60kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 46.6MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waGZbf2lQecU",
        "colab_type": "text"
      },
      "source": [
        "1. Start a spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38wD9dnQI3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ee5a1b4f-4358-4163-e70e-6660a04b7ee2"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\")\n",
        "sparknlp.version()\n",
        "print(\"Apache Spark version\")\n",
        "spark.version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkY9_suMRP1j",
        "colab_type": "text"
      },
      "source": [
        "# QUICK START"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTjBn-LaRSyY",
        "colab_type": "text"
      },
      "source": [
        "NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pWYhLK4QexI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGnpBsm8QrOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cb4f1063-ea75-4ca7-e046-9b3b6c9b3dc7"
      },
      "source": [
        "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 159 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maQsEc72QsA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('Is SparkNLP the best NLP library?') "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WeU78fkQ59K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8261c1b5-c0a1-4aa7-a898-939c10a8b510"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'entities': ['NLP'], 'document': ['Is SparkNLP the best NLP library?'], 'token': ['Is', 'SparkNLP', 'the', 'best', 'NLP', 'library', '?'], 'ner': ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O'], 'embeddings': ['Is', 'SparkNLP', 'the', 'best', 'NLP', 'library', '?'], 'sentence': ['Is SparkNLP the best NLP library?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEDiayEeRVX-",
        "colab_type": "text"
      },
      "source": [
        "Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqhZqThDQ-ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3cb2aec2-4c1f-4618-86b8-466c35c0f73f"
      },
      "source": [
        "pipeline = PretrainedPipeline('analyze_sentiment', 'en')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_cViYGRJVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d5c57d65-ed0e-40b8-9b49-8bb417ad5370"
      },
      "source": [
        "pipeline.annotate('Is SparkNLP the best NLP library?')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['Is', 'SparkNLP', 'the', 'best', 'NLP', 'library', '?'],\n",
              " 'document': ['Is SparkNLP the best NLP library?'],\n",
              " 'sentence': ['Is SparkNLP the best NLP library?'],\n",
              " 'sentiment': ['negative'],\n",
              " 'token': ['Is', 'SparkNLP', 'the', 'best', 'NLP', 'library', '?']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWIGKQvpR3fk",
        "colab_type": "text"
      },
      "source": [
        "# Text CLassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxJ0bRypSwNp",
        "colab_type": "text"
      },
      "source": [
        "Now let’s see how this can be done in Spark NLP using Annotators and Transformers. Assume that we have the following steps that need to be applied one by one on a data frame.\n",
        "\n",
        "Split text into sentences\n",
        "\n",
        "Tokenize\n",
        "\n",
        "Normalize\n",
        "\n",
        "Get word embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNWhEnMDTvuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "44f97595-3bf4-4f14-8fa9-0a1e6451c3c9"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n",
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_train.csv\")\n",
        "trainDataset.show(10, truncate=50)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 16:35:22--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24032125 (23M) [text/plain]\n",
            "Saving to: ‘news_category_train.csv’\n",
            "\n",
            "news_category_train 100%[===================>]  22.92M  40.5MB/s    in 0.6s    \n",
            "\n",
            "2020-07-15 16:35:26 (40.5 MB/s) - ‘news_category_train.csv’ saved [24032125/24032125]\n",
            "\n",
            "--2020-07-15 16:35:27--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1504408 (1.4M) [text/plain]\n",
            "Saving to: ‘news_category_test.csv’\n",
            "\n",
            "news_category_test. 100%[===================>]   1.43M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-15 16:35:28 (11.5 MB/s) - ‘news_category_test.csv’ saved [1504408/1504408]\n",
            "\n",
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "|Business| Stocks ended slightly higher on Friday but sta...|\n",
            "|Business| Assets of the nation's retail money market mut...|\n",
            "|Business| Retail sales bounced back a bit in July, and n...|\n",
            "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
            "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYsvkc_-UvRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "de06ef4d-405c-4160-9992-74084354e9be"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "trainDataset.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World|30000|\n",
            "|Sci/Tech|30000|\n",
            "|  Sports|30000|\n",
            "|Business|30000|\n",
            "+--------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPbC-TmNVT3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "62fd82d4-212a-4fb8-f12f-643542b3e7d9"
      },
      "source": [
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_test.csv\")\n",
        "testDataset.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World| 1900|\n",
            "|  Sports| 1900|\n",
            "|Sci/Tech| 1900|\n",
            "|Business| 1900|\n",
            "+--------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XTttyKCVY_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# document assembler\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24WkLSNyVij9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8c755404-a95d-4f2e-b5b8-14b4d7a42dbe"
      },
      "source": [
        "# downloading pretrained embeddings\n",
        "use = UniversalSentenceEncoder.pretrained()\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su5x-YNEVmLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"category\")\\\n",
        "  .setMaxEpochs(5)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "\n",
        "use_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classsifierdl\n",
        "    ])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jKRJiaRWA2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_pipelineModel = use_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHVqYseWBds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e873f1ff-b13a-4cb3-bc13-9482f6cecba2"
      },
      "source": [
        "preds = use_pipelineModel.transform(testDataset)\n",
        "preds.show(10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|category|         description|            document| sentence_embeddings|               class|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Business|Unions representi...|[[document, 0, 12...|[[sentence_embedd...|[[category, 0, 12...|\n",
            "|Sci/Tech| TORONTO, Canada ...|[[document, 0, 22...|[[sentence_embedd...|[[category, 0, 22...|\n",
            "|Sci/Tech| A company founde...|[[document, 0, 20...|[[sentence_embedd...|[[category, 0, 20...|\n",
            "|Sci/Tech| It's barely dawn...|[[document, 0, 26...|[[sentence_embedd...|[[category, 0, 26...|\n",
            "|Sci/Tech| Southern Califor...|[[document, 0, 17...|[[sentence_embedd...|[[category, 0, 17...|\n",
            "|Sci/Tech|\"The British Depa...|[[document, 0, 10...|[[sentence_embedd...|[[category, 0, 10...|\n",
            "|Sci/Tech|\"confessed author...|[[document, 0, 34...|[[sentence_embedd...|[[category, 0, 34...|\n",
            "|Sci/Tech|\\\\FOAF/LOAF  and ...|[[document, 0, 70...|[[sentence_embedd...|[[category, 0, 70...|\n",
            "|Sci/Tech|\"Wiltshire Police...|[[document, 0, 84...|[[sentence_embedd...|[[category, 0, 84...|\n",
            "|Sci/Tech|In its first two ...|[[document, 0, 13...|[[sentence_embedd...|[[category, 0, 13...|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1T5I4LeWi4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd5c243f-ed3b-4236-b720-55cddb888807"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "df = preds.select('description','category','class.result').toPandas()\n",
        "\n",
        "df['pred_category'] = df['result'].apply(lambda x: x[0])\n",
        "\n",
        "print(classification_report(df['category'], df['pred_category']))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.85      0.84      0.84      1900\n",
            "    Sci/Tech       0.84      0.89      0.87      1900\n",
            "      Sports       0.96      0.98      0.97      1900\n",
            "       World       0.93      0.86      0.89      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.89      7600\n",
            "weighted avg       0.89      0.89      0.89      7600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6xyFH4-X0hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}